+++
title = "Digging into \"Your Brain on ChatGPT\""
date = "2025-09-10"
description = "How educational is a 20 minute SAT essay, really?"
[taxonomies]
categories = ["Blog"]
tags = ["AI", "education", "research", "critique"]
+++

You’ve probably seen the headlines:

“AI shortcuts are already making kids lazy"”“ChatGPT Use Linked to Cognitive Decline”“Using ChatGPT for work? It might make you stupid.”

These stories reference [a recent MIT study](https://arxiv.org/abs/2506.08872) titled *“*Your Brain on ChatGPT*.”* And these headlines, plus the way the study was framed, are the kind of sensationalized science communication that makes thoughtful conversations about AI and education harder to have.

## Yes, I worry about AI and education

I’m big on AI. I work in enterprise AI and see how these tools can free people for more joyful, creative, high-impact work. I also have a young child, and I worry about what her education will look like when she and her peers have access to AI from day one.

But this study doesn’t address those concerns. Instead, it amplifies fears with dramatic interpretations that go far beyond what the research actually shows. 

## This didn’t study education

Here’s what the MIT researchers did:

- Recruited 54 college students.

- Paid them $100–150.

- Asked them to respond to an essay prompt for 20 minutes with EEG caps measuring brain activity.

- To get a “baseline” of thinking activity, participants spent two minutes doing rapid mental math, like multiplying 128 × 56 or adding 5,689 + 7,854 in their heads.

- Then they wrote short essays responding to SAT-style prompts like:

  - “Does true loyalty require unconditional support?”

  - “Can people have too much enthusiasm?”

Some used ChatGPT, some used Google, some wrote without digital tools. The study took place over four months, with each participant completing three or four sessions over that time period.

The paper claims, in the first paragraph of the abstract, to study “the cognitive cost of using an LLM in the educational context of writing an essay.” But what’s *educational* about this setup?

- No instruction.

- No feedback.

- No grades.

- No goal.

- Generic SAT prompts with no iteration or follow-through.

- And you can’t move your head because it will mess up the signals.

When the session ended, students didn’t walk away with insight or skill. They walked to the sink with shampoo and a towel to wash EEG gel out of their hair.

In classrooms, students have grades, improvement, feedback**.** Stakes shape engagement, as does actual interest in the topic. None of that was present here.

This wasn’t education. It showed what happens when you introduce a tool to help with an otherwise tedious, one-off task.

## Study findings

Here’s my summary of the key findings. And yes, if you’re coming from the belief that AI *causes a cognitive deficit*, these findings could look alarming:

- Students using AI showed different patterns of brain connectivity compared to those writing without assistance.

- Their brains showed less coordinated activity across multiple regions.

- They had trouble recalling quotes from essays they’d written minutes earlier.

- Many reported feeling less ownership over their work.

- By the third session, some students said ChatGPT felt “not reliable” for research or “not worth it” for certain assignments.

- In the fourth session, sequence mattered:

  - Students who started without AI and later used it showed increased brain activity.

  - Students who started with AI and then wrote alone showed continued reduced engagement.

But to me, the reason we can’t extrapolate further is because this study felt much more like a tedious activity than an educational opportunity.

It was more like giving students a worksheet of 20 long-division problems that they weren’t graded on and wouldn’t see again. If some used a calculator and some didn’t, would you expect the calculator group to remember the exact numbers they punched in? Probably not — they’d just do it and move on.

Additionally, two teachers evaluated the essays and rated the ChatGPT-assisted essays lower. But as far I can tell, participants never saw those grades and never got feedback. And each session was a new prompt. Without iteration or direction, there was no chance or incentive for any real education.

Researchers measured brain activity, then declared what it meant. Reduced connectivity = cognitive decline? Maybe. But it could also reflect efficiency, new strategies, or adaptation to a new tool.

## Moving forward

I don’t take issue with doing exploratory lab studies like this or the methods used. My issues are the mismatch between the design and the claims about “education,” and the assumptions the researchers seemed to make.

The abstract declares the study’s goal is to “demonstrate the pressing matter of a likely decrease in learning skills.” That doesn’t sound neutral or unbiased.

Further research should add:

- Feedback, revision, and iteration

- Real educational stakes

- Projects students care about

- A neutral starting point, not the assumption that AI is a “cognitive cost”

The MIT study really found that **brains adapt when using new tools.** That’s not surprising. Whether that adaptation helps or harms learning depends on design and context.

Sensational headlines about “AI rotting our brains” don’t help us figure that out.

---

I was ranting about this study to my husband and asked if he was equally upset. He replied: *“No more than I am with all the AI companies promising AGI and superalignment by next quarter.”*

Fair point. The hype cycles run in both directions, and both deserve skepticism.
